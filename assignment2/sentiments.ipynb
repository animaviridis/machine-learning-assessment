{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux_functions as aux\n",
    "import bayes\n",
    "import rule_based\n",
    "from rule_based_new import RuleBasedSentimentAnalyser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1  # make n-grams (1 for single word, 2 for bigrams, etc.)\n",
    "PRINT_ERRORS = False\n",
    "conf = dict(n=N, print_errors=PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise datasets and dictionaries\n",
    "sentimentDictionary, sentencesTrain, sentencesTest, sentencesNokia = aux.read_files()\n",
    "\n",
    "# build conditional probabilities using training data\n",
    "pWords = bayes.trainBayes(sentencesTrain, n=N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Naive Bayes)\t Accuracy (All)=0.89 (8545/9592)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Precision (Pos)=0.90 (4210/4689)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Pos)=0.88 (4210/4778)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Pos)=0.89\n",
      "Films (Train Data, Naive Bayes)\t Precision (Neg)=0.88 (4335/4903)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Neg)=0.90 (4335/4814)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Neg)=0.89\n"
     ]
    }
   ],
   "source": [
    "# run naive bayes classifier on datasets\n",
    "bayes.testBayes(sentencesTrain,  \"Films (Train Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Naive Bayes)\t Accuracy (All)=0.77 (820/1071)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Pos)=0.80 (407/512)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Pos)=0.74 (407/553)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Pos)=0.76\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Neg)=0.74 (413/559)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Neg)=0.80 (413/518)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Neg)=0.77\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesTest,  \"Films  (Test Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data,  Naive Bayes)\t Accuracy (All)=0.59 (157/266)\n",
      "\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Pos)=0.79 (106/135)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Pos)=0.57 (106/186)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Pos)=0.66\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Neg)=0.39 (51/131)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Neg)=0.64 (51/80)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Neg)=0.49\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesNokia, \"Nokia   (All Data,  Naive Bayes)\\t\", *pWords, 0.7, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based)\t Accuracy (All)=0.62 (5993/9592)\n",
      "\n",
      "Films (Train Data, Rule-Based)\t Precision (Pos)=0.59 (3863/6547)\n",
      "Films (Train Data, Rule-Based)\t Recall (Pos)=0.81 (3863/4778)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Pos)=0.68\n",
      "Films (Train Data, Rule-Based)\t Precision (Neg)=0.70 (2130/3045)\n",
      "Films (Train Data, Rule-Based)\t Recall (Neg)=0.44 (2130/4814)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Neg)=0.54\n"
     ]
    }
   ],
   "source": [
    "# run sentiment dictionary based classifier on datasets\n",
    "rule_based.testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based)\t Accuracy (All)=0.64 (684/1071)\n",
      "\n",
      "Films  (Test Data, Rule-Based)\t Precision (Pos)=0.62 (438/710)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Pos)=0.79 (438/553)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Pos)=0.69\n",
      "Films  (Test Data, Rule-Based)\t Precision (Neg)=0.68 (246/361)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Neg)=0.48 (246/518)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Neg)=0.56\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesTest,  \"Films  (Test Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based)\t Accuracy (All)=0.80 (213/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Pos)=0.80 (178/223)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Pos)=0.96 (178/186)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Pos)=0.87\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Neg)=0.82 (35/43)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Neg)=0.44 (35/80)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print most useful words\n",
    "useful = aux.mostUseful(*pWords, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['badly', 'unfunny', 'generic', 'mediocre', 'routine', 'shallow', 'boring', 'purpose', 'shoot', 'mindless', 'stale', 'pointless', 'poorly', 'unless', 'apparently', 'tiresome', 'bore', 'stupid', 'meandering', 'annoying', 'plodding', 'mistake', 'animal', 'banal', 'harvard', 'offensive', 'product', 'seagal', 'lousy', 'lifeless', 'chan', 'disguise', 'pinocchio', 'flat', 'supposed', 'numbers', 'dull', 'inept', 'clich√©', 'kung', 'fatal', 'sadly', 'ballistic', 'uninspired', 'waste', 'junk', 'stealing', 'retread', 'insights', 'lame']\n"
     ]
    }
   ],
   "source": [
    "print(useful['NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absorbing', 'wrenching', 'format', 'understands', 'sides', 'polished', 'unexpected', 'intimate', 'vibrant', 'frailty', 'sly', 'explores', 'literary', 'smarter', 'assured', 'warm', 'martha', 'iranian', 'powerful', 'resonant', 'lively', 'tour', 'spare', 'grown', 'wry', 'subversive', 'touching', 'provides', 'playful', 'captivating', 'respect', 'detailed', 'tender', 'vividly', 'chilling', 'heartwarming', 'captures', 'extraordinary', 'haunting', 'wonderfully', 'gem', 'realistic', 'unique', 'mesmerizing', 'refreshing', 'riveting', 'refreshingly', 'inventive', 'engrossing', 'wonderful']\n"
     ]
    }
   ],
   "source": [
    "print(useful['POSITIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_positive, dict_negative = (dict(filter(lambda i: i[1]==v, sentimentDictionary.items())) for v in [1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_positive.keys() for w in useful['POSITIVE'])  # how many of the positive useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_negative.keys() for w in useful['NEGATIVE'])  # how many of the negative useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based approach - new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbsa = RuleBasedSentimentAnalyser(sentimentDictionary, print_errors=PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based (new))\t Accuracy (All)=0.63 (6071/9592)\n",
      "\n",
      "Films (Train Data, Rule-Based (new))\t Precision (Pos)=0.60 (3783/6309)\n",
      "Films (Train Data, Rule-Based (new))\t Recall (Pos)=0.79 (3783/4778)\n",
      "Films (Train Data, Rule-Based (new))\t F-measure (Pos)=0.68\n",
      "Films (Train Data, Rule-Based (new))\t Precision (Neg)=0.70 (2288/3283)\n",
      "Films (Train Data, Rule-Based (new))\t Recall (Neg)=0.48 (2288/4814)\n",
      "Films (Train Data, Rule-Based (new))\t F-measure (Neg)=0.57\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesTrain,  \"Films (Train Data, Rule-Based (new))\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based (new))\t Accuracy (All)=0.65 (693/1071)\n",
      "\n",
      "Films  (Test Data, Rule-Based (new))\t Precision (Pos)=0.63 (432/689)\n",
      "Films  (Test Data, Rule-Based (new))\t Recall (Pos)=0.78 (432/553)\n",
      "Films  (Test Data, Rule-Based (new))\t F-measure (Pos)=0.70\n",
      "Films  (Test Data, Rule-Based (new))\t Precision (Neg)=0.68 (261/382)\n",
      "Films  (Test Data, Rule-Based (new))\t Recall (Neg)=0.50 (261/518)\n",
      "Films  (Test Data, Rule-Based (new))\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesTest, \"Films  (Test Data, Rule-Based (new))\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based (new))\t Accuracy (All)=0.82 (217/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based (new))\t Precision (Pos)=0.82 (175/213)\n",
      "Nokia   (All Data, Rule-Based (new))\t Recall (Pos)=0.94 (175/186)\n",
      "Nokia   (All Data, Rule-Based (new))\t F-measure (Pos)=0.88\n",
      "Nokia   (All Data, Rule-Based (new))\t Precision (Neg)=0.80 (42/53)\n",
      "Nokia   (All Data, Rule-Based (new))\t Recall (Neg)=0.53 (42/80)\n",
      "Nokia   (All Data, Rule-Based (new))\t F-measure (Neg)=0.64\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesNokia, \"Nokia   (All Data, Rule-Based (new))\\t\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
