{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux_functions as aux\n",
    "import bayes\n",
    "import rule_based\n",
    "from rule_based_new import RuleBasedSentimentAnalyser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1  # make n-grams (1 for single word, 2 for bigrams, etc.)\n",
    "PRINT_ERRORS = False\n",
    "conf = dict(n=N, print_errors=PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise datasets and dictionaries\n",
    "sentimentDictionary, sentencesTrain, sentencesTest, sentencesNokia = aux.read_files()\n",
    "sentencesFilms = {**sentencesTrain, **sentencesTest}  # merge the two dictionaries\n",
    "\n",
    "# build conditional probabilities using training data\n",
    "pWords = bayes.trainBayes(sentencesTrain, n=N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Naive Bayes classifier on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Naive Bayes)\t Accuracy (All)=0.89 (8559/9605)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Precision (Pos)=0.90 (4236/4730)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Pos)=0.88 (4236/4788)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Pos)=0.89\n",
      "Films (Train Data, Naive Bayes)\t Precision (Neg)=0.89 (4323/4875)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Neg)=0.90 (4323/4817)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Neg)=0.89\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesTrain,  \"Films (Train Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Naive Bayes)\t Accuracy (All)=0.78 (827/1059)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Pos)=0.81 (408/504)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Pos)=0.75 (408/544)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Pos)=0.78\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Neg)=0.76 (419/555)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Neg)=0.81 (419/515)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Neg)=0.78\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesTest,  \"Films  (Test Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data,  Naive Bayes)\t Accuracy (All)=0.58 (154/266)\n",
      "\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Pos)=0.77 (105/136)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Pos)=0.57 (105/186)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Pos)=0.65\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Neg)=0.38 (49/130)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Neg)=0.62 (49/80)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Neg)=0.47\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesNokia, \"Nokia   (All Data,  Naive Bayes)\\t\", *pWords, 0.7, **conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sentiment dictionary based classifier on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based)\t Accuracy (All)=0.62 (5980/9605)\n",
      "\n",
      "Films (Train Data, Rule-Based)\t Precision (Pos)=0.59 (3855/6547)\n",
      "Films (Train Data, Rule-Based)\t Recall (Pos)=0.81 (3855/4788)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Pos)=0.68\n",
      "Films (Train Data, Rule-Based)\t Precision (Neg)=0.69 (2125/3058)\n",
      "Films (Train Data, Rule-Based)\t Recall (Neg)=0.44 (2125/4817)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Neg)=0.54\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based)\t Accuracy (All)=0.66 (698/1059)\n",
      "\n",
      "Films  (Test Data, Rule-Based)\t Precision (Pos)=0.63 (447/711)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Pos)=0.82 (447/544)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Pos)=0.71\n",
      "Films  (Test Data, Rule-Based)\t Precision (Neg)=0.72 (251/348)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Neg)=0.49 (251/515)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesTest,  \"Films  (Test Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based)\t Accuracy (All)=0.80 (213/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Pos)=0.80 (178/223)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Pos)=0.96 (178/186)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Pos)=0.87\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Neg)=0.82 (35/43)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Neg)=0.44 (35/80)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful words\n",
    "print most useful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful = aux.mostUseful(*pWords, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mediocre', 'generic', 'badly', 'unfunny', 'routine', 'lame', 'poorly', 'mindless', 'boring', 'bore', 'disguise', 'stale', 'tiresome', 'pointless', 'offensive', 'superficial', 'shoot', 'meandering', 'annoying', 'thinks', 'product', 'stupid', 'unless', 'animal', 'horrible', 'chan', 'wasted', 'pinocchio', 'junk', 'banal', 'harvard', 'fatal', 'sadly', 'incoherent', 'lifeless', 'seagal', 'supposed', 'waste', 'dull', 'cliched', 'inept', 'collection', 'sentiment', 'amateurish', 'meant', 'kung', 'pathetic', 'trite', 'missed', 'pile']\n"
     ]
    }
   ],
   "source": [
    "print(useful['NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['understands', 'timely', 'poem', 'unflinching', 'breathtaking', 'visceral', 'ingenious', 'captivating', 'hopeful', 'poignant', 'startling', 'iranian', 'powerful', 'format', 'heartbreaking', 'grown', 'jealousy', 'transcends', 'literary', 'subversive', 'spare', 'unexpected', 'provides', 'resonant', 'tour', 'polished', 'wry', 'vividly', 'chilling', 'captures', 'tender', 'playful', 'respect', 'heartwarming', 'wonderfully', 'detailed', 'pulls', 'lively', 'warm', 'gem', 'mesmerizing', 'realistic', 'refreshing', 'refreshingly', 'haunting', 'riveting', 'intimate', 'inventive', 'wonderful', 'engrossing']\n"
     ]
    }
   ],
   "source": [
    "print(useful['POSITIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how many of the words are in the respective parts of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_positive, dict_negative = (dict(filter(lambda i: i[1]==v, sentimentDictionary.items())) for v in [1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_positive.keys() for w in useful['POSITIVE'])  # how many of the positive useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_negative.keys() for w in useful['NEGATIVE'])  # how many of the negative useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in sentimentDictionary.keys() for w in useful['POSITIVE'])  # search the entire dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in sentimentDictionary.keys() for w in useful['NEGATIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based approach - new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbsa = RuleBasedSentimentAnalyser(sentimentDictionary, print_errors=PRINT_ERRORS)  # initialise the analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Films dataset\n",
    "Run the analysis for the entire films set (avoid result variation due to random split of the set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (All Data, New Rule-Based)\t Accuracy (All)=0.63 (6765/10663)\n",
      "\n",
      "Films (All Data, New Rule-Based)\t Precision (Pos)=0.60 (4216/6998)\n",
      "Films (All Data, New Rule-Based)\t Recall (Pos)=0.79 (4216/5332)\n",
      "Films (All Data, New Rule-Based)\t F-measure (Pos)=0.68\n",
      "Films (All Data, New Rule-Based)\t Precision (Neg)=0.70 (2549/3665)\n",
      "Films (All Data, New Rule-Based)\t Recall (Neg)=0.48 (2549/5331)\n",
      "Films (All Data, New Rule-Based)\t F-measure (Neg)=0.57\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesFilms,  \"Films (All Data, New Rule-Based)\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to the original approach on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (All Data, Rule-Based)\t Accuracy (All)=0.62 (5980/9605)\n",
      "\n",
      "Films (All Data, Rule-Based)\t Precision (Pos)=0.59 (3855/6547)\n",
      "Films (All Data, Rule-Based)\t Recall (Pos)=0.81 (3855/4788)\n",
      "Films (All Data, Rule-Based)\t F-measure (Pos)=0.68\n",
      "Films (All Data, Rule-Based)\t Precision (Neg)=0.69 (2125/3058)\n",
      "Films (All Data, Rule-Based)\t Recall (Neg)=0.44 (2125/4817)\n",
      "Films (All Data, Rule-Based)\t F-measure (Neg)=0.54\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesTrain,  \"Films (All Data, Rule-Based)\\t\", sentimentDictionary, 0, PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nokia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, New Rule-Based)\t Accuracy (All)=0.82 (217/266)\n",
      "\n",
      "Nokia   (All Data, New Rule-Based)\t Precision (Pos)=0.82 (175/213)\n",
      "Nokia   (All Data, New Rule-Based)\t Recall (Pos)=0.94 (175/186)\n",
      "Nokia   (All Data, New Rule-Based)\t F-measure (Pos)=0.88\n",
      "Nokia   (All Data, New Rule-Based)\t Precision (Neg)=0.80 (42/53)\n",
      "Nokia   (All Data, New Rule-Based)\t Recall (Neg)=0.53 (42/80)\n",
      "Nokia   (All Data, New Rule-Based)\t F-measure (Neg)=0.64\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesNokia, \"Nokia   (All Data, New Rule-Based)\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to the original approach again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based)\t Accuracy (All)=0.80 (213/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Pos)=0.80 (178/223)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Pos)=0.96 (178/186)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Pos)=0.87\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Neg)=0.82 (35/43)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Neg)=0.44 (35/80)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
