{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux_functions as aux\n",
    "import bayes\n",
    "import rule_based\n",
    "from rule_based_new import RuleBasedSentimentAnalyser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1  # make n-grams (1 for single word, 2 for bigrams, etc.)\n",
    "PRINT_ERRORS = False\n",
    "conf = dict(n=N, print_errors=PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise datasets and dictionaries\n",
    "sentimentDictionary, sentencesTrain, sentencesTest, sentencesNokia = aux.read_files()\n",
    "\n",
    "# build conditional probabilities using training data\n",
    "pWords = bayes.trainBayes(sentencesTrain, n=N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Naive Bayes)\t Accuracy (All)=0.89 (8515/9589)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Precision (Pos)=0.90 (4206/4687)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Pos)=0.88 (4206/4799)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Pos)=0.89\n",
      "Films (Train Data, Naive Bayes)\t Precision (Neg)=0.88 (4309/4902)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Neg)=0.90 (4309/4790)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Neg)=0.89\n"
     ]
    }
   ],
   "source": [
    "# run naive bayes classifier on datasets\n",
    "bayes.testBayes(sentencesTrain,  \"Films (Train Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Naive Bayes)\t Accuracy (All)=0.77 (827/1074)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Pos)=0.77 (411/537)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Pos)=0.77 (411/532)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Pos)=0.77\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Neg)=0.78 (416/537)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Neg)=0.77 (416/542)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Neg)=0.77\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesTest,  \"Films  (Test Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data,  Naive Bayes)\t Accuracy (All)=0.59 (158/266)\n",
      "\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Pos)=0.79 (106/134)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Pos)=0.57 (106/186)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Pos)=0.66\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Neg)=0.40 (52/132)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Neg)=0.65 (52/80)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Neg)=0.50\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesNokia, \"Nokia   (All Data,  Naive Bayes)\\t\", *pWords, 0.7, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based)\t Accuracy (All)=0.62 (5991/9589)\n",
      "\n",
      "Films (Train Data, Rule-Based)\t Precision (Pos)=0.59 (3861/6521)\n",
      "Films (Train Data, Rule-Based)\t Recall (Pos)=0.80 (3861/4799)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Pos)=0.68\n",
      "Films (Train Data, Rule-Based)\t Precision (Neg)=0.69 (2130/3068)\n",
      "Films (Train Data, Rule-Based)\t Recall (Neg)=0.44 (2130/4790)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Neg)=0.54\n"
     ]
    }
   ],
   "source": [
    "# run sentiment dictionary based classifier on datasets\n",
    "rule_based.testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based)\t Accuracy (All)=0.64 (686/1074)\n",
      "\n",
      "Films  (Test Data, Rule-Based)\t Precision (Pos)=0.60 (440/736)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Pos)=0.83 (440/532)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Pos)=0.69\n",
      "Films  (Test Data, Rule-Based)\t Precision (Neg)=0.73 (246/338)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Neg)=0.45 (246/542)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Neg)=0.56\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesTest,  \"Films  (Test Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based)\t Accuracy (All)=0.80 (213/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Pos)=0.80 (178/223)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Pos)=0.96 (178/186)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Pos)=0.87\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Neg)=0.82 (35/43)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Neg)=0.44 (35/80)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print most useful words\n",
    "useful = aux.mostUseful(*pWords, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generic', 'stupid', 'unfunny', 'mediocre', 'routine', 'badly', 'pointless', 'poorly', 'boring', 'bore', 'tiresome', 'disguise', 'mindless', 'unless', 'apparently', 'stale', 'save', 'offensive', 'meandering', 'chan', 'annoying', 'shoot', 'product', 'animal', 'amateurish', 'fatal', 'seagal', 'pinocchio', 'dull', 'flat', 'designed', 'preachy', 'waste', 'pass', 'deserve', 'horrible', 'harvard', 'mistake', 'sadly', 'plodding', 'supposed', 'built', 'ill', 'stealing', 'inept', 'lame', 'banal', 'pathetic', 'incoherent', 'ballistic']\n"
     ]
    }
   ],
   "source": [
    "print(useful['NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spare', 'sides', 'transcends', 'breathtaking', 'frailty', 'richly', 'sadness', 'smarter', 'martha', 'playful', 'startling', 'powerful', 'unexpected', 'heartbreaking', 'timely', 'grown', 'jealousy', 'warm', 'record', 'literary', 'portrait', 'tender', 'detailed', 'tour', 'captivating', 'respect', 'provides', 'iranian', 'lively', 'striking', 'polished', 'wonderfully', 'wonderful', 'wry', 'vividly', 'heartwarming', 'deftly', 'chilling', 'unique', 'gem', 'delicate', 'mesmerizing', 'realistic', 'refreshingly', 'riveting', 'skin', 'refreshing', 'inventive', 'captures', 'engrossing']\n"
     ]
    }
   ],
   "source": [
    "print(useful['POSITIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_positive, dict_negative = (dict(filter(lambda i: i[1]==v, sentimentDictionary.items())) for v in [1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_positive.keys() for w in useful['POSITIVE'])  # how many of the positive useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_negative.keys() for w in useful['NEGATIVE'])  # how many of the negative useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based approach - new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbsa = RuleBasedSentimentAnalyser(sentimentDictionary, print_errors=PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based (new))\t Accuracy (All)=0.63 (6067/9589)\n",
      "\n",
      "Films (Train Data, Rule-Based (new))\t Precision (Pos)=0.60 (3767/6257)\n",
      "Films (Train Data, Rule-Based (new))\t Recall (Pos)=0.79 (3767/4799)\n",
      "Films (Train Data, Rule-Based (new))\t F-measure (Pos)=0.68\n",
      "Films (Train Data, Rule-Based (new))\t Precision (Neg)=0.69 (2300/3332)\n",
      "Films (Train Data, Rule-Based (new))\t Recall (Neg)=0.48 (2300/4790)\n",
      "Films (Train Data, Rule-Based (new))\t F-measure (Neg)=0.57\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesTrain,  \"Films (Train Data, Rule-Based (new))\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based (new))\t Accuracy (All)=0.64 (683/1074)\n",
      "\n",
      "Films  (Test Data, Rule-Based (new))\t Precision (Pos)=0.60 (416/691)\n",
      "Films  (Test Data, Rule-Based (new))\t Recall (Pos)=0.78 (416/532)\n",
      "Films  (Test Data, Rule-Based (new))\t F-measure (Pos)=0.68\n",
      "Films  (Test Data, Rule-Based (new))\t Precision (Neg)=0.70 (267/383)\n",
      "Films  (Test Data, Rule-Based (new))\t Recall (Neg)=0.49 (267/542)\n",
      "Films  (Test Data, Rule-Based (new))\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesTest, \"Films  (Test Data, Rule-Based (new))\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based (new))\t Accuracy (All)=0.82 (217/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based (new))\t Precision (Pos)=0.82 (177/217)\n",
      "Nokia   (All Data, Rule-Based (new))\t Recall (Pos)=0.95 (177/186)\n",
      "Nokia   (All Data, Rule-Based (new))\t F-measure (Pos)=0.88\n",
      "Nokia   (All Data, Rule-Based (new))\t Precision (Neg)=0.82 (40/49)\n",
      "Nokia   (All Data, Rule-Based (new))\t Recall (Neg)=0.51 (40/80)\n",
      "Nokia   (All Data, Rule-Based (new))\t F-measure (Neg)=0.63\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesNokia, \"Nokia   (All Data, Rule-Based (new))\\t\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
