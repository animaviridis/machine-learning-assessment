{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux_functions as aux\n",
    "import bayes\n",
    "import rule_based\n",
    "from rule_based_new import RuleBasedSentimentAnalyser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1  # make n-grams (1 for single word, 2 for bigrams, etc.)\n",
    "PRINT_ERRORS = False\n",
    "conf = dict(n=N, print_errors=PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise datasets and dictionaries\n",
    "sentimentDictionary, sentencesTrain, sentencesTest, sentencesNokia = aux.read_files()\n",
    "\n",
    "# build conditional probabilities using training data\n",
    "pWords = bayes.trainBayes(sentencesTrain, n=N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Naive Bayes)\t Accuracy (All)=0.89 (8519/9567)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Precision (Pos)=0.90 (4189/4662)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Pos)=0.88 (4189/4764)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Pos)=0.89\n",
      "Films (Train Data, Naive Bayes)\t Precision (Neg)=0.88 (4330/4905)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Neg)=0.90 (4330/4803)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Neg)=0.89\n"
     ]
    }
   ],
   "source": [
    "# run naive bayes classifier on datasets\n",
    "bayes.testBayes(sentencesTrain,  \"Films (Train Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Naive Bayes)\t Accuracy (All)=0.77 (846/1097)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Pos)=0.79 (435/553)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Pos)=0.77 (435/568)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Pos)=0.78\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Neg)=0.76 (411/544)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Neg)=0.78 (411/529)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Neg)=0.77\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesTest,  \"Films  (Test Data, Naive Bayes)\\t\", *pWords, 0.5, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data,  Naive Bayes)\t Accuracy (All)=0.59 (157/266)\n",
      "\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Pos)=0.79 (105/133)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Pos)=0.57 (105/186)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Pos)=0.66\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Neg)=0.40 (52/133)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Neg)=0.65 (52/80)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Neg)=0.49\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesNokia, \"Nokia   (All Data,  Naive Bayes)\\t\", *pWords, 0.7, **conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based)\t Accuracy (All)=0.63 (6004/9567)\n",
      "\n",
      "Films (Train Data, Rule-Based)\t Precision (Pos)=0.59 (3857/6513)\n",
      "Films (Train Data, Rule-Based)\t Recall (Pos)=0.81 (3857/4764)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Pos)=0.68\n",
      "Films (Train Data, Rule-Based)\t Precision (Neg)=0.70 (2147/3054)\n",
      "Films (Train Data, Rule-Based)\t Recall (Neg)=0.45 (2147/4803)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Neg)=0.55\n"
     ]
    }
   ],
   "source": [
    "# run sentiment dictionary based classifier on datasets\n",
    "rule_based.testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based)\t Accuracy (All)=0.61 (674/1097)\n",
      "\n",
      "Films  (Test Data, Rule-Based)\t Precision (Pos)=0.60 (445/745)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Pos)=0.78 (445/568)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Pos)=0.68\n",
      "Films  (Test Data, Rule-Based)\t Precision (Neg)=0.65 (229/352)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Neg)=0.43 (229/529)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Neg)=0.52\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesTest,  \"Films  (Test Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based)\t Accuracy (All)=0.80 (213/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Pos)=0.80 (178/223)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Pos)=0.96 (178/186)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Pos)=0.87\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Neg)=0.82 (35/43)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Neg)=0.44 (35/80)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, 0, PRINT_ERRORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print most useful words\n",
    "useful = aux.mostUseful(*pWords, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flat', 'stupid', 'generic', 'unfunny', 'mediocre', 'badly', 'routine', 'poorly', 'mindless', 'pointless', 'disguise', 'bears', 'dull', 'boring', 'unless', 'stale', 'shoot', 'offensive', 'annoying', 'meandering', 'harvard', 'manipulative', 'bore', 'mistake', 'designed', 'lousy', 'tv', 'junk', 'stealing', 'waste', 'animal', 'apparently', 'horrible', 'banal', 'kung', 'fatal', 'cliched', 'tiresome', 'product', 'incoherent', 'plodding', 'uninspired', 'lame', 'built', 'ill', 'inept', 'chan', 'wasted', 'unintentional', 'amateurish']\n"
     ]
    }
   ],
   "source": [
    "print(useful['NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['russian', 'potent', 'grown', 'poem', 'pianist', 'transcends', 'explores', 'record', 'spare', 'resonant', 'sadness', 'masterpiece', 'spooky', 'powerful', 'unexpected', 'iranian', 'sides', \"world's\", 'son', 'gentle', 'provides', 'tender', 'martha', 'intense', 'detailed', 'tour', 'captivating', 'jealousy', 'portrait', 'wonderfully', 'glimpse', 'playful', 'lively', 'polished', 'wonderful', 'respect', 'nicely', 'vividly', 'captures', 'wry', 'heartwarming', 'chilling', 'refreshingly', 'gem', 'mesmerizing', 'refreshing', 'realistic', 'riveting', 'inventive', 'engrossing']\n"
     ]
    }
   ],
   "source": [
    "print(useful['POSITIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_positive, dict_negative = (dict(filter(lambda i: i[1]==v, sentimentDictionary.items())) for v in [1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_positive.keys() for w in useful['POSITIVE'])  # how many of the positive useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_negative.keys() for w in useful['NEGATIVE'])  # how many of the negative useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based approach - new implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbsa = RuleBasedSentimentAnalyser(sentimentDictionary, print_errors=PRINT_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based (new))\t Accuracy (All)=0.63 (6004/9567)\n",
      "\n",
      "Films (Train Data, Rule-Based (new))\t Precision (Pos)=0.59 (3857/6513)\n",
      "Films (Train Data, Rule-Based (new))\t Recall (Pos)=0.81 (3857/4764)\n",
      "Films (Train Data, Rule-Based (new))\t F-measure (Pos)=0.68\n",
      "Films (Train Data, Rule-Based (new))\t Precision (Neg)=0.70 (2147/3054)\n",
      "Films (Train Data, Rule-Based (new))\t Recall (Neg)=0.45 (2147/4803)\n",
      "Films (Train Data, Rule-Based (new))\t F-measure (Neg)=0.55\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesTrain,  \"Films (Train Data, Rule-Based (new))\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based (new))\t Accuracy (All)=0.61 (674/1097)\n",
      "\n",
      "Films  (Test Data, Rule-Based (new))\t Precision (Pos)=0.60 (445/745)\n",
      "Films  (Test Data, Rule-Based (new))\t Recall (Pos)=0.78 (445/568)\n",
      "Films  (Test Data, Rule-Based (new))\t F-measure (Pos)=0.68\n",
      "Films  (Test Data, Rule-Based (new))\t Precision (Neg)=0.65 (229/352)\n",
      "Films  (Test Data, Rule-Based (new))\t Recall (Neg)=0.43 (229/529)\n",
      "Films  (Test Data, Rule-Based (new))\t F-measure (Neg)=0.52\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesTest, \"Films  (Test Data, Rule-Based (new))\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based (new))\t Accuracy (All)=0.80 (213/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based (new))\t Precision (Pos)=0.80 (178/223)\n",
      "Nokia   (All Data, Rule-Based (new))\t Recall (Pos)=0.96 (178/186)\n",
      "Nokia   (All Data, Rule-Based (new))\t F-measure (Pos)=0.87\n",
      "Nokia   (All Data, Rule-Based (new))\t Precision (Neg)=0.82 (35/43)\n",
      "Nokia   (All Data, Rule-Based (new))\t Recall (Neg)=0.44 (35/80)\n",
      "Nokia   (All Data, Rule-Based (new))\t F-measure (Neg)=0.58\n"
     ]
    }
   ],
   "source": [
    "rbsa.evaluate(sentencesNokia, \"Nokia   (All Data, Rule-Based (new))\\t\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
