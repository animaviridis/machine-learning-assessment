{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aux_functions as aux\n",
    "import bayes\n",
    "import rule_based\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise datasets and dictionaries\n",
    "sentimentDictionary, sentencesTrain, sentencesTest, sentencesNokia = aux.read_files()\n",
    "\n",
    "N = 1  # make n-grams (1 for single word, 2 for bigrams, etc.)\n",
    "\n",
    "# build conditional probabilities using training data\n",
    "pWordPos, pWordNeg, pWord = bayes.trainBayes(sentencesTrain, n=N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Naive Bayes)\t Accuracy (All)=0.89 (8543/9572)\n",
      "\n",
      "Films (Train Data, Naive Bayes)\t Precision (Pos)=0.90 (4224/4677)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Pos)=0.88 (4224/4800)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Pos)=0.89\n",
      "Films (Train Data, Naive Bayes)\t Precision (Neg)=0.88 (4319/4895)\n",
      "Films (Train Data, Naive Bayes)\t Recall (Neg)=0.91 (4319/4772)\n",
      "Films (Train Data, Naive Bayes)\t F-measure (Neg)=0.89\n"
     ]
    }
   ],
   "source": [
    "# run naive bayes classifier on datasets\n",
    "bayes.testBayes(sentencesTrain,  \"Films (Train Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5, n=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Naive Bayes)\t Accuracy (All)=0.79 (857/1091)\n",
      "\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Pos)=0.79 (403/509)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Pos)=0.76 (403/531)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Pos)=0.78\n",
      "Films  (Test Data, Naive Bayes)\t Precision (Neg)=0.78 (454/582)\n",
      "Films  (Test Data, Naive Bayes)\t Recall (Neg)=0.81 (454/560)\n",
      "Films  (Test Data, Naive Bayes)\t F-measure (Neg)=0.80\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesTest,  \"Films  (Test Data, Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.5, n=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data,  Naive Bayes)\t Accuracy (All)=0.60 (159/266)\n",
      "\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Pos)=0.79 (109/139)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Pos)=0.59 (109/186)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Pos)=0.67\n",
      "Nokia   (All Data,  Naive Bayes)\t Precision (Neg)=0.40 (50/127)\n",
      "Nokia   (All Data,  Naive Bayes)\t Recall (Neg)=0.63 (50/80)\n",
      "Nokia   (All Data,  Naive Bayes)\t F-measure (Neg)=0.49\n"
     ]
    }
   ],
   "source": [
    "bayes.testBayes(sentencesNokia, \"Nokia   (All Data,  Naive Bayes)\\t\", pWordPos, pWordNeg, pWord,0.7, n=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films (Train Data, Rule-Based)\t Accuracy (All)=0.50 (4831/9572)\n",
      "\n",
      "Films (Train Data, Rule-Based)\t Precision (Pos)=0.50 (4791/9523)\n",
      "Films (Train Data, Rule-Based)\t Recall (Pos)=1.00 (4791/4800)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Pos)=0.67\n",
      "Films (Train Data, Rule-Based)\t Precision (Neg)=0.82 (40/49)\n",
      "Films (Train Data, Rule-Based)\t Recall (Neg)=0.01 (40/4772)\n",
      "Films (Train Data, Rule-Based)\t F-measure (Neg)=0.02\n"
     ]
    }
   ],
   "source": [
    "# run sentiment dictionary based classifier on datasets\n",
    "rule_based.testDictionary(sentencesTrain,  \"Films (Train Data, Rule-Based)\\t\", sentimentDictionary, -4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Films  (Test Data, Rule-Based)\t Accuracy (All)=0.49 (533/1091)\n",
      "\n",
      "Films  (Test Data, Rule-Based)\t Precision (Pos)=0.49 (530/1087)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Pos)=1.00 (530/531)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Pos)=0.66\n",
      "Films  (Test Data, Rule-Based)\t Precision (Neg)=0.80 (3/4)\n",
      "Films  (Test Data, Rule-Based)\t Recall (Neg)=0.01 (3/560)\n",
      "Films  (Test Data, Rule-Based)\t F-measure (Neg)=0.01\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesTest,  \"Films  (Test Data, Rule-Based)\\t\",  sentimentDictionary, -4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nokia   (All Data, Rule-Based)\t Accuracy (All)=0.70 (186/266)\n",
      "\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Pos)=0.70 (186/266)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Pos)=1.00 (186/186)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Pos)=0.82\n",
      "Nokia   (All Data, Rule-Based)\t Precision (Neg)=1.00 (0/0)\n",
      "Nokia   (All Data, Rule-Based)\t Recall (Neg)=0.01 (0/80)\n",
      "Nokia   (All Data, Rule-Based)\t F-measure (Neg)=0.02\n"
     ]
    }
   ],
   "source": [
    "rule_based.testDictionary(sentencesNokia, \"Nokia   (All Data, Rule-Based)\\t\",  sentimentDictionary, -3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print most useful words\n",
    "useful = aux.mostUseful(pWordPos, pWordNeg, pWord, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boring', 'routine', 'waste', 'badly', 'unfunny', 'mediocre', 'generic', 'poorly', 'mindless', 'stale', 'offensive', 'pointless', 'bore', 'disguise', 'annoying', 'dull', 'mixed', 'unless', 'harvard', 'shoot', 'tiresome', 'pinocchio', 'numbers', 'stupid', 'disaster', 'meandering', 'banal', 'chan', 'wasted', 'product', 'plodding', 'stealing', 'animal', 'amateurish', 'kung', 'pathetic', 'ballistic', 'seagal', 'uninspired', 'supposed', 'ill', 'junk', 'bother', 'lame', 'apparently', 'horrible', 'trite', 'fatal', 'pile', 'lousy']\n"
     ]
    }
   ],
   "source": [
    "print(useful['NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subversive', 'timely', 'smarter', 'thoughtful', 'warm', 'evocative', 'spooky', 'martha', 'hearts', 'playful', 'powerful', 'resonant', 'aspects', 'tour', 'captivating', 'capture', 'record', 'spare', 'consistently', 'touching', 'provides', 'flaws', 'iranian', 'unexpected', 'polished', 'strength', 'depiction', 'assured', 'respect', 'heartwarming', 'captures', 'detailed', 'lively', 'wry', 'vividly', 'quietly', 'wonderful', 'intense', 'mesmerizing', 'chilling', 'wonderfully', 'refreshingly', 'refreshing', 'gem', 'ages', 'unique', 'realistic', 'riveting', 'inventive', 'engrossing']\n"
     ]
    }
   ],
   "source": [
    "print(useful['POSITIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_positive, dict_negative = (dict(filter(lambda i: i[1]==v, sentimentDictionary.items())) for v in [1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_positive.keys() for w in useful['POSITIVE'])  # how many of the positive useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(w in dict_negative.keys() for w in useful['NEGATIVE'])  # how many of the negative useful words appear in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
